{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "153d3fde",
      "metadata": {
        "id": "153d3fde"
      },
      "source": [
        "\n",
        "# Using PyTorch profiler for FLOPS and Model Sizing\n",
        "\n",
        "Hi everyone, here's how you can measure FLOPS in GB and FLOPS of your model. Useful for the lab and project!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b6db8d8b",
      "metadata": {
        "id": "b6db8d8b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.profiler import profile, ProfilerActivity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22c1013f",
      "metadata": {
        "id": "22c1013f"
      },
      "source": [
        "###  Define a Simple CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll have to define your model first in order to use the torch profiler and run it through one forward pass with a dummy input to track the FLOPS and parameters. Below is a simple CNN with 3 increasing filters, a max pool, fc layers, and RELU. Since we're using pytorch operations, they get counted in the pytorch profiler."
      ],
      "metadata": {
        "id": "n525X-3p9_QA"
      },
      "id": "n525X-3p9_QA"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c338d7ab",
      "metadata": {
        "id": "c338d7ab"
      },
      "outputs": [],
      "source": [
        "\n",
        "#for CIFAR10\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(4 * 4 * 128, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 4 * 4 * 128)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea95a239",
      "metadata": {
        "id": "ea95a239"
      },
      "source": [
        "### Count Parameters & Model Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fc5e7278",
      "metadata": {
        "id": "fc5e7278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0822ff93-c8f0-48fd-e032-4d4d881ac028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 1,147,466\n",
            "Model Size: 1.15 M parameters\n",
            "Model Size: 0.004274643957614899 GB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#we set our model to what we defined earlier\n",
        "model = SimpleCNN()\n",
        "\n",
        "param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total Parameters: {param_count:,}\")\n",
        "param_count_m = param_count / 1_000_000  # convert to millions (used for lab grading!!!)\n",
        "print(f\"Model Size: {param_count_m:.2f} M parameters\")\n",
        "model_size_gb = param_count * 4 / (1024 * 1024 * 1024)\n",
        "print(f\"Model Size: {model_size_gb} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec5b015",
      "metadata": {
        "id": "aec5b015"
      },
      "source": [
        "### Forward Pass Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "28be2222",
      "metadata": {
        "id": "28be2222",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89c5ca6-6335-47e1-b85a-8a3c2745f3fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dummy_input = torch.randn(1, 3, 32, 32)  #batch size of one, we use random numbers as dummy input\n",
        "model.eval() #do not update the gradients, just evaluate\n",
        "with torch.no_grad(): #run it through\n",
        "    output = model(dummy_input)\n",
        "print(\"Output shape:\", output.shape) #10 classes for cifar-10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42049121",
      "metadata": {
        "id": "42049121"
      },
      "source": [
        "###  FLOP Profiling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "af07771d",
      "metadata": {
        "id": "af07771d"
      },
      "outputs": [],
      "source": [
        "#Note THAT profileracitvity is set for CPU but can be set to .CUDA to run on cuda\n",
        "#if you're setting it for CUDA, make sure to also set the cuda for the model as well\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU],record_shapes=True,with_flops=True) as prof:\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "events = prof.events()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d92180",
      "metadata": {
        "id": "58d92180"
      },
      "source": [
        "###  Total FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "62528291",
      "metadata": {
        "id": "62528291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffa2088-5019-4175-ab4c-9db13c01e588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FLOPs: 22,751,232\n",
            "GFLOPs: 0.023\n"
          ]
        }
      ],
      "source": [
        "\n",
        "total_flops = sum(e.flops for e in events if e.flops is not None)\n",
        "print(f\"Total FLOPs: {total_flops:,}\")\n",
        "print(f\"GFLOPs: {total_flops / 1e9:.3f}\") #1e9 moves it three decimal places\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f2bcd98",
      "metadata": {
        "id": "1f2bcd98"
      },
      "source": [
        "###  Top 10 Most Expensive Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a6d74a62",
      "metadata": {
        "id": "a6d74a62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bef9f07-5c95-486d-a7bc-7f1f22f19fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most expensive operations:\n",
            " 1. aten::conv2d                                  |    9,437,184 FLOPs ( 41.5%)\n",
            " 2. aten::conv2d                                  |    9,437,184 FLOPs ( 41.5%)\n",
            " 3. aten::addmm                                   |    2,097,152 FLOPs (  9.2%)\n",
            " 4. aten::conv2d                                  |    1,769,472 FLOPs (  7.8%)\n",
            " 5. aten::addmm                                   |       10,240 FLOPs (  0.0%)\n",
            " 6. aten::view                                    |            0 FLOPs (  0.0%)\n",
            " 7. aten::view                                    |            0 FLOPs (  0.0%)\n",
            " 8. aten::view                                    |            0 FLOPs (  0.0%)\n",
            " 9. aten::view                                    |            0 FLOPs (  0.0%)\n",
            "10. aten::view                                    |            0 FLOPs (  0.0%)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "flop_events = [(e.flops, e.key) for e in events if e.flops is not None]\n",
        "flop_events.sort(reverse=True)\n",
        "\n",
        "print(\"Top 10 most expensive operations:\")\n",
        "for i, (flops, op) in enumerate(flop_events[:10]): #top 10\n",
        "    pct = (flops / total_flops) * 100\n",
        "    print(f\"{i+1:2d}. {op[:45]:45s} | {flops:>12,} FLOPs ({pct:5.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "420c3b84",
      "metadata": {
        "id": "420c3b84"
      },
      "source": [
        "### Layer-by-Layer Parameter Breakdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0d7abe86",
      "metadata": {
        "id": "0d7abe86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653b7db1-74f8-4520-b787-90db03983f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer parameter breakdown:\n",
            "conv1                     |        896 params\n",
            "conv2                     |     18,496 params\n",
            "conv3                     |     73,856 params\n",
            "fc1                       |  1,049,088 params\n",
            "fc2                       |      5,130 params\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Layer parameter breakdown:\")\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, (nn.Conv1d, nn.Conv2d, nn.Linear)): #include more nn modules here to check layers\n",
        "        layer_params = sum(p.numel() for p in module.parameters())\n",
        "        print(f\"{name:25s} | {layer_params:>10,} params\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9909cf7f",
      "metadata": {
        "id": "9909cf7f"
      },
      "source": [
        "\n",
        "### Paste your model here\n",
        "\n",
        "Replace `SimpleCNN` with your own model below and re-run the steps if you want to calculate the Gflops, parameters in M.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ffd80ede",
      "metadata": {
        "id": "ffd80ede"
      },
      "outputs": [],
      "source": [
        "\n",
        "# class someModel(nn.Module):\n",
        "#......................\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}